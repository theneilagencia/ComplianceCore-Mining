"""
Radar AI - Monitoramento Regulat√≥rio Global
============================================
M√≥dulo respons√°vel por detectar, analisar e alertar sobre mudan√ßas
regulat√≥rias em normas internacionais de minera√ß√£o (ANM, JORC, NI43-101, PERC, SAMREC).

Author: QIVO Intelligence Platform
Version: 5.0.0
Date: 2025-11-01
"""

import asyncio
import json
from datetime import datetime, timezone
from typing import Dict, List, Optional, Any
from openai import AsyncOpenAI
import os

# Metadados das fontes regulat√≥rias
REGULATORY_SOURCES = {
    "ANM": {
        "country": "Brasil",
        "full_name": "Ag√™ncia Nacional de Minera√ß√£o",
        "url": "https://www.gov.br/anm/pt-br",
        "focus": ["licenciamento", "seguran√ßa operacional", "impacto ambiental"],
        "language": "pt-BR",
        "update_frequency": "mensal"
    },
    "JORC": {
        "country": "Austr√°lia",
        "full_name": "Joint Ore Reserves Committee",
        "url": "https://www.jorc.org",
        "focus": ["recursos minerais", "reservas", "transpar√™ncia"],
        "language": "en-AU",
        "update_frequency": "anual"
    },
    "NI43-101": {
        "country": "Canad√°",
        "full_name": "National Instrument 43-101",
        "url": "https://www.osc.ca",
        "focus": ["divulga√ß√£o t√©cnica", "persons qualificadas", "due diligence"],
        "language": "en-CA",
        "update_frequency": "trimestral"
    },
    "PERC": {
        "country": "R√∫ssia",
        "full_name": "Pan-European Reserves and Resources Reporting Committee",
        "url": "https://www.vnimi.ru",
        "focus": ["recursos pan-europeus", "harmoniza√ß√£o", "classifica√ß√£o geol√≥gica"],
        "language": "ru-RU",
        "update_frequency": "semestral"
    },
    "SAMREC": {
        "country": "√Åfrica do Sul",
        "full_name": "South African Mineral Resource Committee",
        "url": "https://www.samcode.co.za",
        "focus": ["recursos minerais", "reservas", "c√≥digo sul-africano"],
        "language": "en-ZA",
        "update_frequency": "anual"
    }
}

# N√≠veis de severidade
SEVERITY_LEVELS = {
    "Low": {"score": 1, "color": "üü¢", "threshold": 0.3},
    "Medium": {"score": 2, "color": "üü°", "threshold": 0.5},
    "High": {"score": 3, "color": "üü†", "threshold": 0.75},
    "Critical": {"score": 4, "color": "üî¥", "threshold": 0.9}
}


class RadarEngine:
    """
    Engine de monitoramento regulat√≥rio que detecta, analisa e alerta
    sobre mudan√ßas em normas globais de minera√ß√£o.
    """
    
    def __init__(self, api_key: Optional[str] = None):
        """
        Inicializa o Radar Engine.
        
        Args:
            api_key: OpenAI API key (opcional, usa env var se n√£o fornecida)
        """
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        self.client = AsyncOpenAI(api_key=self.api_key) if self.api_key else None
        self.sources = REGULATORY_SOURCES
        self.cache: Dict[str, Any] = {}  # Cache de vers√µes anteriores
        
    def get_supported_sources(self) -> List[str]:
        """Retorna lista de fontes regulat√≥rias suportadas."""
        return list(self.sources.keys())
    
    def get_source_metadata(self, source: str) -> Optional[Dict[str, Any]]:
        """
        Retorna metadados de uma fonte espec√≠fica.
        
        Args:
            source: Nome da fonte (ANM, JORC, etc.)
            
        Returns:
            Dict com metadados ou None se fonte n√£o existir
        """
        return self.sources.get(source)
    
    async def fetch_sources(
        self, 
        sources: Optional[List[str]] = None
    ) -> Dict[str, Dict[str, Any]]:
        """
        Busca dados atualizados de fontes regulat√≥rias.
        
        Em produ√ß√£o, isso conectaria a APIs reais, web scrapers,
        ou feeds RSS das ag√™ncias regulat√≥rias.
        
        Args:
            sources: Lista de fontes para monitorar (default: todas)
            
        Returns:
            Dict com dados estruturados de cada fonte
        """
        target_sources = sources or self.get_supported_sources()
        results = {}
        
        for source in target_sources:
            if source not in self.sources:
                continue
            
            # Simula√ß√£o de dados (em produ√ß√£o, seria scraping real)
            metadata = self.sources[source]
            results[source] = {
                "metadata": metadata,
                "fetched_at": datetime.now(timezone.utc).isoformat(),
                "status": "active",
                "latest_updates": self._simulate_source_data(source),
                "version": self._get_source_version(source)
            }
            
            # Simula delay de rede
            await asyncio.sleep(0.1)
        
        return results
    
    def _simulate_source_data(self, source: str) -> List[Dict[str, Any]]:
        """
        Simula dados de atualiza√ß√£o de uma fonte.
        Em produ√ß√£o, isso seria substitu√≠do por parsing real.
        """
        # Simula√ß√µes realistas baseadas em cada norma
        simulations = {
            "ANM": [
                {
                    "title": "Resolu√ß√£o ANM n¬∫ 125/2025 - Novos requisitos para barragens",
                    "date": "2025-10-15",
                    "type": "regulatory_change",
                    "impact": "high",
                    "summary": "Estabelece novos crit√©rios de seguran√ßa para barragens de minera√ß√£o classe C e D"
                },
                {
                    "title": "Portaria ANM n¬∫ 89/2025 - Atualiza√ß√£o de taxas",
                    "date": "2025-10-20",
                    "type": "administrative",
                    "impact": "medium",
                    "summary": "Reajuste anual de taxas de fiscaliza√ß√£o"
                }
            ],
            "JORC": [
                {
                    "title": "JORC Code 2025 - Amendment 3",
                    "date": "2025-09-30",
                    "type": "code_update",
                    "impact": "critical",
                    "summary": "Introduz requisitos adicionais para reporting de recursos em √°reas sens√≠veis"
                }
            ],
            "NI43-101": [
                {
                    "title": "CSA Staff Notice 43-309 - ESG Disclosure",
                    "date": "2025-10-01",
                    "type": "guidance",
                    "impact": "high",
                    "summary": "Novas diretrizes sobre divulga√ß√£o de fatores ESG em relat√≥rios t√©cnicos"
                }
            ],
            "PERC": [
                {
                    "title": "PERC Standard 2025 - Harmoniza√ß√£o com CRIRSCO",
                    "date": "2025-08-15",
                    "type": "standard_update",
                    "impact": "medium",
                    "summary": "Alinhamento de terminologia com padr√µes internacionais CRIRSCO"
                }
            ],
            "SAMREC": [
                {
                    "title": "SAMREC Code 2025 Edition",
                    "date": "2025-07-01",
                    "type": "code_revision",
                    "impact": "high",
                    "summary": "Revis√£o completa do c√≥digo incluindo novos requisitos para minera√ß√£o profunda"
                }
            ]
        }
        
        return simulations.get(source, [])
    
    def _get_source_version(self, source: str) -> str:
        """Retorna vers√£o atual da fonte (simulado)."""
        versions = {
            "ANM": "v2025.10",
            "JORC": "v2025.3",
            "NI43-101": "v2025.Q3",
            "PERC": "v2025.2",
            "SAMREC": "v2025.1"
        }
        return versions.get(source, "v1.0")
    
    async def analyze_changes(
        self,
        current_data: Dict[str, Dict[str, Any]],
        deep: bool = False
    ) -> List[Dict[str, Any]]:
        """
        Analisa mudan√ßas detectadas comparando com vers√µes anteriores.
        
        Args:
            current_data: Dados atuais das fontes
            deep: Se True, faz an√°lise sem√¢ntica profunda com GPT
            
        Returns:
            Lista de mudan√ßas detectadas com metadados
        """
        changes = []
        
        for source, data in current_data.items():
            # Compara com cache (vers√£o anterior)
            cached_version = self.cache.get(source, {}).get("version")
            current_version = data.get("version")
            
            if cached_version != current_version:
                # Detectou mudan√ßa de vers√£o
                for update in data.get("latest_updates", []):
                    change = {
                        "source": source,
                        "change_type": update.get("type", "unknown"),
                        "title": update.get("title", ""),
                        "date": update.get("date", ""),
                        "impact_level": update.get("impact", "low"),
                        "summary": update.get("summary", ""),
                        "detected_at": datetime.now(timezone.utc).isoformat(),
                        "version_change": f"{cached_version or 'N/A'} ‚Üí {current_version}"
                    }
                    changes.append(change)
            
            # Atualiza cache
            self.cache[source] = data
        
        # An√°lise profunda com GPT se solicitado
        if deep and self.client and changes:
            changes = await self._deep_analyze_changes(changes)
        
        return changes
    
    async def _deep_analyze_changes(
        self,
        changes: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        Realiza an√°lise sem√¢ntica profunda das mudan√ßas usando GPT-4o.
        """
        if not self.client:
            return changes
        
        # Prepara contexto para an√°lise
        context = json.dumps(changes, indent=2, ensure_ascii=False)
        
        prompt = f"""Voc√™ √© um especialista em regulamenta√ß√£o de minera√ß√£o internacional.

Analise as seguintes mudan√ßas regulat√≥rias detectadas e forne√ßa:
1. Avalia√ß√£o de impacto operacional (0-100)
2. N√≠vel de urg√™ncia (Low, Medium, High, Critical)
3. Recomenda√ß√µes de a√ß√£o
4. Palavras-chave de risco

Mudan√ßas detectadas:
{context}

Responda em JSON com este formato:
{{
  "analysis": [
    {{
      "source": "fonte",
      "impact_score": 85,
      "severity": "High",
      "urgency": "30 dias",
      "recommendations": ["a√ß√£o 1", "a√ß√£o 2"],
      "risk_keywords": ["palavra1", "palavra2"],
      "explanation": "an√°lise detalhada"
    }}
  ]
}}"""

        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um analista de compliance regulat√≥rio especializado em minera√ß√£o."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                response_format={"type": "json_object"}
            )
            
            analysis = json.loads(response.choices[0].message.content)
            
            # Enriquece os changes com an√°lise GPT
            for i, change in enumerate(changes):
                if i < len(analysis.get("analysis", [])):
                    gpt_analysis = analysis["analysis"][i]
                    change.update({
                        "gpt_impact_score": gpt_analysis.get("impact_score", 0),
                        "gpt_severity": gpt_analysis.get("severity", "Low"),
                        "gpt_urgency": gpt_analysis.get("urgency", ""),
                        "gpt_recommendations": gpt_analysis.get("recommendations", []),
                        "gpt_risk_keywords": gpt_analysis.get("risk_keywords", []),
                        "gpt_explanation": gpt_analysis.get("explanation", "")
                    })
            
        except Exception as e:
            # Fallback se GPT falhar
            for change in changes:
                change["gpt_error"] = str(e)
        
        return changes
    
    def generate_alerts(
        self,
        changes: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        Gera alertas classificados por severidade.
        
        Args:
            changes: Lista de mudan√ßas detectadas
            
        Returns:
            Lista de alertas com severidade e confian√ßa
        """
        alerts = []
        
        for change in changes:
            # Determina severidade baseado em m√∫ltiplos fatores
            severity = self._calculate_severity(change)
            confidence = self._calculate_confidence(change)
            
            alert = {
                "source": change.get("source", "unknown"),
                "change": change.get("title", ""),
                "severity": severity,
                "confidence": round(confidence, 2),
                "summary": change.get("summary", ""),
                "date": change.get("date", ""),
                "impact_level": change.get("impact_level", "low"),
                "recommendations": change.get("gpt_recommendations", []),
                "risk_keywords": change.get("gpt_risk_keywords", []),
                "version_change": change.get("version_change", ""),
                "detected_at": change.get("detected_at", "")
            }
            
            # Adiciona explica√ß√£o GPT se dispon√≠vel
            if "gpt_explanation" in change:
                alert["gpt_analysis"] = change["gpt_explanation"]
            
            alerts.append(alert)
        
        # Ordena por severidade (Critical ‚Üí High ‚Üí Medium ‚Üí Low)
        severity_order = {"Critical": 0, "High": 1, "Medium": 2, "Low": 3}
        alerts.sort(key=lambda x: (severity_order.get(x["severity"], 4), -x["confidence"]))
        
        return alerts
    
    def _calculate_severity(self, change: Dict[str, Any]) -> str:
        """
        Calcula severidade baseado em m√∫ltiplos indicadores.
        """
        # Se GPT forneceu severidade, usa ela
        if "gpt_severity" in change:
            return change["gpt_severity"]
        
        # Fallback: mapeia impact_level para severity
        impact_map = {
            "critical": "Critical",
            "high": "High",
            "medium": "Medium",
            "low": "Low"
        }
        
        impact = change.get("impact_level", "low").lower()
        return impact_map.get(impact, "Low")
    
    def _calculate_confidence(self, change: Dict[str, Any]) -> float:
        """
        Calcula confian√ßa da detec√ß√£o (0-1).
        """
        confidence = 0.5  # Base
        
        # Aumenta se tem an√°lise GPT
        if "gpt_impact_score" in change:
            gpt_score = change["gpt_impact_score"] / 100.0
            confidence = 0.3 + (gpt_score * 0.7)
        
        # Aumenta se tem mudan√ßa de vers√£o confirmada
        if "version_change" in change and "N/A" not in change["version_change"]:
            confidence = min(confidence + 0.15, 1.0)
        
        # Aumenta se tem data recente
        if "date" in change:
            try:
                change_date = datetime.fromisoformat(change["date"].replace("Z", "+00:00"))
                days_ago = (datetime.now(timezone.utc) - change_date).days
                if days_ago < 30:
                    confidence = min(confidence + 0.1, 1.0)
            except:
                pass
        
        return confidence
    
    async def summarize(self, findings: Dict[str, Any]) -> str:
        """
        Gera resumo executivo dos achados usando GPT-4o.
        
        Args:
            findings: Dict com timestamp e alerts
            
        Returns:
            String com resumo executivo
        """
        if not self.client:
            return self._generate_basic_summary(findings)
        
        alerts = findings.get("alerts", [])
        if not alerts:
            return "Nenhuma mudan√ßa regulat√≥ria detectada no per√≠odo."
        
        context = json.dumps(alerts, indent=2, ensure_ascii=False)
        
        prompt = f"""Voc√™ √© um consultor de compliance regulat√≥rio na minera√ß√£o.

Gere um resumo executivo profissional (3-5 par√°grafos) sobre as mudan√ßas regulat√≥rias detectadas.

Inclua:
- Panorama geral
- Principais riscos e oportunidades
- Prioridades de a√ß√£o
- Impacto em diferentes jurisdi√ß√µes

Dados:
{context}

Seja objetivo, t√©cnico e focado em decis√µes estrat√©gicas."""

        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um especialista em regula√ß√£o de minera√ß√£o global."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=800
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            return self._generate_basic_summary(findings) + f"\n\n[Nota: Erro ao gerar resumo GPT: {str(e)}]"
    
    def _generate_basic_summary(self, findings: Dict[str, Any]) -> str:
        """Gera resumo b√°sico sem GPT."""
        alerts = findings.get("alerts", [])
        
        if not alerts:
            return "Nenhuma mudan√ßa regulat√≥ria detectada."
        
        total = len(alerts)
        by_severity = {}
        for alert in alerts:
            sev = alert.get("severity", "Low")
            by_severity[sev] = by_severity.get(sev, 0) + 1
        
        summary = f"Detectadas {total} mudan√ßas regulat√≥rias:\n"
        for sev in ["Critical", "High", "Medium", "Low"]:
            if sev in by_severity:
                emoji = SEVERITY_LEVELS[sev]["color"]
                summary += f"  {emoji} {sev}: {by_severity[sev]}\n"
        
        return summary.strip()
    
    async def run_cycle(
        self,
        sources: Optional[List[str]] = None,
        deep: bool = False,
        summarize: bool = False
    ) -> Dict[str, Any]:
        """
        Executa ciclo completo de monitoramento.
        
        Args:
            sources: Fontes para monitorar (default: todas)
            deep: Ativa an√°lise profunda com GPT
            summarize: Gera resumo executivo
            
        Returns:
            Dict com timestamp, alerts e summary (se solicitado)
        """
        # 1. Busca dados das fontes
        current_data = await self.fetch_sources(sources)
        
        # 2. Analisa mudan√ßas
        changes = await self.analyze_changes(current_data, deep=deep)
        
        # 3. Gera alertas
        alerts = self.generate_alerts(changes)
        
        # 4. Monta resultado
        result = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "sources_monitored": list(current_data.keys()),
            "alerts_count": len(alerts),
            "alerts": alerts
        }
        
        # 5. Gera resumo se solicitado
        if summarize and alerts:
            result["executive_summary"] = await self.summarize(result)
        
        return result


# Singleton para uso global
_radar_instance: Optional[RadarEngine] = None

def get_radar_engine() -> RadarEngine:
    """Retorna inst√¢ncia singleton do RadarEngine."""
    global _radar_instance
    if _radar_instance is None:
        _radar_instance = RadarEngine()
    return _radar_instance
